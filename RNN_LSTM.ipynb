{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: protobuf==3.20.* in /opt/anaconda3/lib/python3.8/site-packages (3.20.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3.8 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install protobuf==3.20.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "import music21\n",
    "import os\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1972\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1720\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1716\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=2011\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-391.43073    155.47241     17.796213  ...   -4.6647406    3.875946\n",
      "   -15.378936 ]\n",
      " [-393.21747    147.7681       4.0019064 ...   -0.7845236    8.864843\n",
      "   -24.797276 ]\n",
      " [-419.03735    124.122314   -10.7456455 ...   -1.1820716   10.188527\n",
      "   -24.609009 ]\n",
      " ...\n",
      " [-574.42633     98.704926    23.784882  ...   -7.4547267  -14.941587\n",
      "   -18.76279  ]\n",
      " [-568.67847    112.97853     27.634674  ...  -12.145161   -15.410059\n",
      "   -15.896633 ]\n",
      " [-547.70917    140.97972     35.77067   ...   -9.35202    -14.029166\n",
      "   -16.116203 ]]\n",
      "[[ 2.1984  2.4922 62.    ]\n",
      " [ 2.5883  2.957  62.    ]\n",
      " [ 2.9922  3.2016 62.    ]\n",
      " ...\n",
      " [73.7356 74.2529 64.    ]\n",
      " [74.2529 74.4396 67.    ]\n",
      " [74.5115 75.9195 65.    ]]\n"
     ]
    }
   ],
   "source": [
    "# Get a list of csv files\n",
    "csv_files = glob.glob(\"data/csv/*.csv\")\n",
    "\n",
    "# Get a list of wav files\n",
    "audio_files = glob.glob(\"data/wav/*.wav\")\n",
    "\n",
    "wav_file_names = {file.split(\"/\")[-1].split(\".\")[0] for file in audio_files}\n",
    "\n",
    "all_mfccs = []\n",
    "all_labels = []\n",
    "\n",
    "for csv_file in csv_files:\n",
    "    \n",
    "    csv_file_name = csv_file.split(\"/\")[-1].split(\".\")[0]\n",
    "    \n",
    "    if csv_file_name in wav_file_names:\n",
    "        # Load the CSV file that contains columns 'start', 'end', 'pitch', 'syllable'\n",
    "        df = pd.read_csv(csv_file)\n",
    "        \n",
    "        # Load and process the audio file corresponding to the row\n",
    "        audio_file = f'data/wav/{csv_file_name}.wav'  \n",
    "        y, sr = librosa.load(audio_file, sr=None)\n",
    "\n",
    "        # Iterate over each row in the DataFrame to process each audio file\n",
    "        for index, row in df.iterrows():\n",
    "            start_time = row['start']\n",
    "            end_time = row['end']\n",
    "            pitch = row['pitch']\n",
    "            syllable = row['syllable']\n",
    "           \n",
    "            start_sample = int(start_time * sr)\n",
    "            end_sample = int(end_time * sr)\n",
    "            audio_segment = y[start_sample:end_sample]\n",
    "            mfccs = librosa.feature.mfcc(y=audio_segment, sr=sr, n_mfcc=13)\n",
    "\n",
    "            # Append MFCCs and labels to the lists\n",
    "            all_mfccs.append(mfccs.T)  # Transpose to have time_steps x features\n",
    "            all_labels.append([start_time, end_time, pitch])\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "all_mfccs = np.concatenate(all_mfccs, axis=0)\n",
    "all_labels = np.array(all_labels)\n",
    "\n",
    "print(all_mfccs)\n",
    "print(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(313614, 13)\n",
      "(8484, 3)\n"
     ]
    }
   ],
   "source": [
    "print(all_mfccs.shape)\n",
    "print(all_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8484, 13)\n"
     ]
    }
   ],
   "source": [
    "filtered_mfccs = all_mfccs[:all_labels.shape[0]]\n",
    "\n",
    "print(filtered_mfccs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(filtered_mfccs, all_labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Reshape features for LSTM input (n_samples, n_timesteps, n_features)\n",
    "X_train_reshaped = X_train_scaled.reshape(X_train_scaled.shape[0], 1, X_train_scaled.shape[1])\n",
    "X_test_reshaped = X_test_scaled.reshape(X_test_scaled.shape[0], 1, X_test_scaled.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (6787, 1, 13)\n",
      "y_train shape: (6787, 3)\n",
      "X_test shape: (1697, 1, 13)\n",
      "y_test shape: (1697, 3)\n"
     ]
    }
   ],
   "source": [
    "# Print shapes \n",
    "print(\"X_train shape:\", X_train_reshaped.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_test shape:\", X_test_reshaped.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "213/213 [==============================] - 4s 6ms/step - loss: 805.2960 - val_loss: 850.5261\n",
      "Epoch 2/10\n",
      "213/213 [==============================] - 1s 3ms/step - loss: 742.5798 - val_loss: 776.3959\n",
      "Epoch 3/10\n",
      "213/213 [==============================] - 1s 3ms/step - loss: 728.2602 - val_loss: 875.6009\n",
      "Epoch 4/10\n",
      "213/213 [==============================] - 1s 2ms/step - loss: 715.0490 - val_loss: 977.1172\n",
      "Epoch 5/10\n",
      "213/213 [==============================] - 1s 3ms/step - loss: 699.3289 - val_loss: 675.6984\n",
      "Epoch 6/10\n",
      "213/213 [==============================] - 1s 3ms/step - loss: 682.8446 - val_loss: 695.7804\n",
      "Epoch 7/10\n",
      "213/213 [==============================] - 1s 3ms/step - loss: 666.7524 - val_loss: 683.9102\n",
      "Epoch 8/10\n",
      "213/213 [==============================] - 1s 3ms/step - loss: 654.4684 - val_loss: 779.0517\n",
      "Epoch 9/10\n",
      "213/213 [==============================] - 1s 2ms/step - loss: 649.7346 - val_loss: 728.3735\n",
      "Epoch 10/10\n",
      "213/213 [==============================] - 1s 2ms/step - loss: 642.7515 - val_loss: 625.7495\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe1dddcb640>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the LSTM model with two LSTM layers \n",
    "model = Sequential()\n",
    "model.add(LSTM(50, return_sequences=True, input_shape=(None, X_train_reshaped.shape[2])))\n",
    "model.add(Dropout(0.2))  # Optional Dropout layer for regularization\n",
    "model.add(LSTM(50))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(50, activation='tanh'))  \n",
    "model.add(Dense(1)) \n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='mse', optimizer='SGD')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_reshaped, y_train, validation_data=(X_test_reshaped, y_test),epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIDI file saved: midi-output/en016b.mid\n",
      "MIDI file saved: midi-output/en020a.mid\n",
      "MIDI file saved: midi-output/en016a.mid\n",
      "MIDI file saved: midi-output/en020b.mid\n",
      "MIDI file saved: midi-output/en021b.mid\n",
      "MIDI file saved: midi-output/en017a.mid\n",
      "MIDI file saved: midi-output/en001a.mid\n",
      "MIDI file saved: midi-output/en021a.mid\n",
      "MIDI file saved: midi-output/en017b.mid\n",
      "MIDI file saved: midi-output/en001b.mid\n",
      "MIDI file saved: midi-output/en006a.mid\n",
      "MIDI file saved: midi-output/en010a.mid\n",
      "MIDI file saved: midi-output/en026b.mid\n",
      "MIDI file saved: midi-output/en006b.mid\n",
      "MIDI file saved: midi-output/en010b.mid\n",
      "MIDI file saved: midi-output/en030a.mid\n",
      "MIDI file saved: midi-output/en026a.mid\n",
      "MIDI file saved: midi-output/en027a.mid\n",
      "MIDI file saved: midi-output/en011b.mid\n",
      "MIDI file saved: midi-output/en007b.mid\n",
      "MIDI file saved: midi-output/en027b.mid\n",
      "MIDI file saved: midi-output/en011a.mid\n",
      "MIDI file saved: midi-output/en007a.mid\n",
      "MIDI file saved: midi-output/en028a.mid\n",
      "MIDI file saved: midi-output/en024b.mid\n",
      "MIDI file saved: midi-output/en012a.mid\n",
      "MIDI file saved: midi-output/en004a.mid\n",
      "MIDI file saved: midi-output/en008b.mid\n",
      "MIDI file saved: midi-output/en028b.mid\n",
      "MIDI file saved: midi-output/en024a.mid\n",
      "MIDI file saved: midi-output/en012b.mid\n",
      "MIDI file saved: midi-output/en004b.mid\n",
      "MIDI file saved: midi-output/en008a.mid\n",
      "MIDI file saved: midi-output/en009a.mid\n",
      "MIDI file saved: midi-output/en005b.mid\n",
      "MIDI file saved: midi-output/en013b.mid\n",
      "MIDI file saved: midi-output/en025a.mid\n",
      "MIDI file saved: midi-output/en029b.mid\n",
      "MIDI file saved: midi-output/en009b.mid\n",
      "MIDI file saved: midi-output/en005a.mid\n",
      "MIDI file saved: midi-output/en013a.mid\n",
      "MIDI file saved: midi-output/en025b.mid\n",
      "MIDI file saved: midi-output/en029a.mid\n",
      "MIDI file saved: midi-output/en022a.mid\n",
      "MIDI file saved: midi-output/en014b.mid\n",
      "MIDI file saved: midi-output/en018a.mid\n",
      "MIDI file saved: midi-output/en002b.mid\n",
      "MIDI file saved: midi-output/en022b.mid\n",
      "MIDI file saved: midi-output/en014a.mid\n",
      "MIDI file saved: midi-output/en018b.mid\n",
      "MIDI file saved: midi-output/en002a.mid\n",
      "MIDI file saved: midi-output/en003a.mid\n",
      "MIDI file saved: midi-output/en019b.mid\n",
      "MIDI file saved: midi-output/en015a.mid\n",
      "MIDI file saved: midi-output/en023b.mid\n",
      "MIDI file saved: midi-output/en003b.mid\n",
      "MIDI file saved: midi-output/en019a.mid\n",
      "MIDI file saved: midi-output/en015b.mid\n",
      "MIDI file saved: midi-output/en023a.mid\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import mido\n",
    "from mido import MidiFile, MidiTrack, Message\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "output_directory = \"midi-output/\"\n",
    "\n",
    "def audio_to_midi(audio_file_path, model, scaler):\n",
    "    # Load and process the audio file\n",
    "    y, sr = librosa.load(audio_file_path, sr=None)\n",
    "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "    mfccs_scaled = scaler.transform(mfccs.T)  \n",
    "    mfccs_reshaped = mfccs_scaled.reshape(1, mfccs_scaled.shape[0], mfccs_scaled.shape[1])\n",
    "\n",
    "    # Predict the labels (e.g., start_time, end_time, pitch) using the model\n",
    "    predictions = model.predict(mfccs_reshaped)\n",
    "\n",
    "    # Post-process the predictions to MIDI format\n",
    "    midi_notes = []\n",
    "    for prediction in predictions[0]: \n",
    "        pitch = int(prediction)  \n",
    "        midi_notes.append((pitch, 256)) \n",
    "\n",
    "    # Create a new MIDI file and track\n",
    "    mid = MidiFile()\n",
    "    track = MidiTrack()\n",
    "    mid.tracks.append(track)\n",
    "\n",
    "    # Add notes to the MIDI track\n",
    "    for note, duration in midi_notes:\n",
    "        track.append(Message('note_on', note=note, velocity=64, time=0))\n",
    "        track.append(Message('note_off', note=note, velocity=64, time=duration))\n",
    "\n",
    "    # Save the MIDI file\n",
    "    audio_file_name = os.path.basename(audio_file_path).replace('.wav', '.mid')\n",
    "    midi_file_path = os.path.join(output_directory, audio_file_name)\n",
    "    mid.save(midi_file_path)\n",
    "    print(f\"MIDI file saved: {midi_file_path}\")\n",
    "\n",
    "# Loop through each WAV file to generate a MIDI file for it\n",
    "for audio_file in audio_files:\n",
    "    audio_to_midi(audio_file, model, scaler)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
