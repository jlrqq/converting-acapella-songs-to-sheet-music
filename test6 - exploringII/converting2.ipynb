{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import joblib\n",
    "from mido import MidiFile, MidiTrack, Message, MetaMessage\n",
    "import pretty_midi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idea is to \n",
    "# 1) extract on and offset\n",
    "# 2) do the same feature extraction method as training\n",
    "# 3) load the model and predict notes\n",
    "# 4) use the onset offset info together convert to midi\n",
    "# 5) convert to sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load audio file\n",
    "audio_path = \"../data/wav/en001b.wav\"\n",
    "audio_data, sr = librosa.load(audio_path)\n",
    "mfccs = librosa.feature.mfcc(y=audio_data, sr=sr, n_mfcc=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract onset and offset timings\n",
    "onset_frames = librosa.onset.onset_detect(y=audio_data, sr=sr, backtrack=True)\n",
    "onset_times = librosa.frames_to_time(onset_frames, sr=sr)\n",
    "offset_times = onset_times[1:].tolist() + [librosa.get_duration(y=audio_data, sr=sr)]  # Assuming offset is the next onset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract tempo\n",
    "tempo, _ = librosa.beat.beat_track(y=audio_data, sr=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(onset_times)<len(offset_times):\n",
    "    offset_times = offset_times[:len(onset_times)]\n",
    "else:\n",
    "    onset_times = onset_times[:len(offset_times)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def align_frames_with_times(mfccs, sr, max_length, onsets, offsets):\n",
    "    frame_times = librosa.frames_to_time(np.arange(len(mfccs.T)), sr=sr)\n",
    "    aligned_features = []\n",
    "\n",
    "    for onset, offset in zip(onsets, offsets):\n",
    "        onset_frame = np.argmax(frame_times >= onset)\n",
    "        offset_frame = np.argmax(frame_times >= offset)\n",
    "        feature_sequence = mfccs[:, onset_frame:offset_frame]\n",
    "\n",
    "        # Pad or truncate feature sequence to the fixed length\n",
    "        if feature_sequence.shape[1] < max_length:\n",
    "            pad_width = max_length - feature_sequence.shape[1]\n",
    "            padded_sequence = np.pad(feature_sequence, ((0, 0), (0, pad_width)), mode='constant')\n",
    "            aligned_features.append(padded_sequence)\n",
    "        else:\n",
    "            truncated_sequence = feature_sequence[:, :max_length]\n",
    "            aligned_features.append(truncated_sequence)\n",
    "\n",
    "    # Convert aligned_features to a numpy array\n",
    "    aligned_features = np.array(aligned_features)\n",
    "\n",
    "    # Mask the padding values\n",
    "    mask = (aligned_features.sum(axis=-1) != 0).astype(np.float32)[:, :, np.newaxis]\n",
    "    masked_features = aligned_features * mask\n",
    "    return masked_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = align_frames_with_times(mfccs, sr, 100, onset_times, offset_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(119, 13, 100)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features.shape\n",
    "# scaler = joblib.load('scaler.pkl')\n",
    "# features_scaled = scaler.transform(features)\n",
    "# f_reshaped = features_scaled.reshape(features_scaled.shape[0],1,features_scaled.shape[1])\n",
    "# f_reshaped = features.reshape(features.shape[0],1,features.shape[1])\n",
    "# f_reshaped = features.reshape(features.shape[0],1,13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(onset_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_14192\\1269163900.py:5: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  pred = [int(i) for i in pred]\n"
     ]
    }
   ],
   "source": [
    "model = load_model('./model.h5')\n",
    "\n",
    "# pred = model.predict(f_reshaped)\n",
    "pred = model.predict(features)\n",
    "pred = [int(i) for i in pred]\n",
    "# pred[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred)\n",
    "# max(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_midi(predicted_pitches, onset_times, offset_times, tempo=120):\n",
    "    # Create a PrettyMIDI object\n",
    "    midi_data = pretty_midi.PrettyMIDI(initial_tempo=tempo)\n",
    "\n",
    "    # Create an Instrument instance for the piano\n",
    "    piano_program = pretty_midi.instrument_name_to_program('Acoustic Grand Piano')\n",
    "    piano = pretty_midi.Instrument(program=piano_program)\n",
    "\n",
    "    # Convert predicted pitches to MIDI notes\n",
    "    for pitch, onset, offset in zip(predicted_pitches, onset_times, offset_times):\n",
    "        note = pretty_midi.Note(\n",
    "            velocity=100, pitch=int(pitch), start=onset, end=offset\n",
    "        )\n",
    "        piano.notes.append(note)\n",
    "\n",
    "    # Add the piano instrument to the PrettyMIDI object\n",
    "    midi_data.instruments.append(piano)\n",
    "\n",
    "    # Write the MIDI data to a file\n",
    "    midi_data.write('output.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_midi(pred, onset_times, offset_times, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mido import MidiFile, MidiTrack, Message\n",
    "\n",
    "midi_file = MidiFile()\n",
    "track = MidiTrack()\n",
    "midi_file.tracks.append(track)\n",
    "\n",
    "# Assuming each predicted pitch has a corresponding duration (e.g., 1 second)\n",
    "for pitch in pred:\n",
    "    track.append(Message('note_on', note=pitch, velocity=64, time=0))\n",
    "    track.append(Message('note_off', note=pitch, velocity=64, time=int(sr)))  # Duration of 1 second\n",
    "\n",
    "midi_file.save('predicted_output.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = '../output/'\n",
    "\n",
    "# Function to convert pitches to MIDI notes\n",
    "def pitches_to_midi(onset_times, offset_times, pitches, output_file_path, tempo=100):\n",
    "    midi = MidiFile()\n",
    "    track = MidiTrack()\n",
    "    midi.tracks.append(track)\n",
    "\n",
    "    ticks_per_beat = 480 #standard MIDI ticks per beat #midi.ticks_per_beat\n",
    "\n",
    "    track.append(MetaMessage('set_tempo', tempo=tempo))\n",
    "\n",
    "    # Assign MIDI note numbers to pitches\n",
    "    min_pitch = min(pred)  # MIDI note number for C4\n",
    "    max_pitch = max(pred)  # MIDI note number for C5\n",
    "    pitch_range = max_pitch - min_pitch\n",
    "\n",
    "    interpolated_pitches = []\n",
    "    for i in range(len(onset_times)-1):\n",
    "        start_time = onset_times[i]\n",
    "        end_time = offset_times[i]\n",
    "        duration = end_time - start_time\n",
    "        num_steps = int(duration * ticks_per_beat)\n",
    "\n",
    "        if num_steps == 0:\n",
    "            continue\n",
    "\n",
    "        start_pitch = pitches[i]\n",
    "        end_pitch = pitches[i+1]\n",
    "        pitch_diff = end_pitch - start_pitch\n",
    "        pitch_step = pitch_diff / num_steps\n",
    "\n",
    "        for step in range(num_steps):\n",
    "            interpolated_pitch = start_pitch + step * pitch_step\n",
    "            interpolated_pitches.append(interpolated_pitch)\n",
    "\n",
    "    current = 0\n",
    "    for pitch in interpolated_pitches:\n",
    "        # Calculate the MIDI note number\n",
    "        predicted_pitch = min_pitch + int((pitch * pitch_range) % pitch_range)\n",
    "\n",
    "        # Create a note-on message\n",
    "        track.append(Message('note_on', note=predicted_pitch, velocity=100, time=current))\n",
    "\n",
    "        # Create a note-off message (assuming a fixed duration for each note, adjust as needed)\n",
    "        track.append(Message('note_off', note=predicted_pitch, velocity=100, time=current + ticks_per_beat))\n",
    "\n",
    "        current += ticks_per_beat\n",
    "\n",
    "\n",
    "\n",
    "    # Save the MIDI file\n",
    "    midi.save(output_file_path + 'output.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitches_to_midi(onset_times, offset_times, pred, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # # Assign MIDI note numbers to pitches\n",
    "    # # You may need to adjust this based on your model's output\n",
    "    # min_pitch = 61  # MIDI note number for C4\n",
    "    # max_pitch = 71  # MIDI note number for C5\n",
    "    # pitch_range = max_pitch - min_pitch\n",
    "\n",
    "    # for onset, offset, pitch in zip(onset_times, offset_times, pitches):\n",
    "    #     # Get the predicted pitch\n",
    "    #     predicted_pitch = min_pitch + (int(pitch * pitch_range)%pitch_range)\n",
    "\n",
    "    #     # Create a note-on message\n",
    "    #     track.append(Message('note_on', note=predicted_pitch, velocity=100, time=int(onset * ticks_per_beat)))\n",
    "\n",
    "    #     # Create a note-off message\n",
    "    #     track.append(Message('note_off', note=predicted_pitch, velocity=100, time=int(offset * ticks_per_beat)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
